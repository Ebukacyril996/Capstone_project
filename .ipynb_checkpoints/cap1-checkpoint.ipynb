{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ac3d8e6-51c9-4d00-bf05-5822ea6957e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CAPSTONE PROJECT; Debt Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1145be9b-f7dd-4fae-ba22-22822d95128c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "#from faker import Faker\n",
    "import random \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3126ac81-4448-4df4-ae32-b2b82a8ba4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faker in c:\\users\\ebuca\\anaconda3\\lib\\site-packages (36.1.1)\n",
      "Requirement already satisfied: tzdata in c:\\users\\ebuca\\anaconda3\\lib\\site-packages (from faker) (2023.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fefbaba2-8655-416c-a422-b2b1738eadce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   bitcoin_date    price  bitcoin_sats  one_dollar_sats\n",
      "0      8/2/2017  2697.85     100000000            37067\n",
      "1      8/3/2017  2777.37     100000000            36005\n",
      "2      8/4/2017  2845.90     100000000            35138\n",
      "3      8/5/2017  3237.07     100000000            30892\n",
      "4      8/6/2017  3189.73     100000000            31351\n",
      "5      8/7/2017  3356.71     100000000            29791\n",
      "6      8/8/2017  3410.45     100000000            29322\n",
      "7      8/9/2017  3330.90     100000000            30022\n",
      "8     8/10/2017  3367.91     100000000            29692\n",
      "9     8/11/2017  3562.59     100000000            28069\n",
      "10    8/12/2017  3800.14     100000000            26315\n",
      "11    8/13/2017  4023.25     100000000            24855\n",
      "12    8/14/2017  4175.70     100000000            23948\n",
      "13    8/15/2017  4149.31     100000000            24100\n",
      "14    8/16/2017  4262.56     100000000            23460\n",
      "15    8/17/2017  4286.92     100000000            23327\n",
      "16    8/18/2017  4097.69     100000000            24404\n",
      "17    8/19/2017  4115.21     100000000            24300\n",
      "18    8/20/2017  4001.23     100000000            24992\n",
      "19    8/21/2017  3935.23     100000000            25411\n"
     ]
    }
   ],
   "source": [
    "btc_data = pd.read_csv(r\"C:\\Users\\ebuca\\OneDrive\\Documents\\DA13\\Python\\projects\\Capstone_project\\btc-usd-max.csv\")\n",
    "#btc_data['bitcoin_date'] = pd.to_datetime(btc_data['bitcoin_date']).dt.date \n",
    "print(btc_data.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf846e36-b028-4e64-b0aa-0e7319c090be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['names', 'profession', 'job_length', 'state', 'homeownership',\n",
      "       'annual_income', 'monthly_wage', 'debt_to_income', 'total_credit_limit',\n",
      "       'total_credit_utilized', 'loan_purpose', 'loan_amount', 'term',\n",
      "       'interest_rate', 'installment', 'total_payment', 'ten_of monthly',\n",
      "       'spent_strategy', 'issue_date', 'payoff_date'],\n",
      "      dtype='object')\n",
      "0   2018-02-01\n",
      "1   2018-01-01\n",
      "2   2018-01-01\n",
      "3   2018-03-01\n",
      "4   2018-02-01\n",
      "Name: issue_date, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\ebuca\\OneDrive\\Documents\\DA13\\Python\\projects\\Capstone_project\\updated_loan_data.csv\")\n",
    "#fake = Faker()\n",
    "#def assign_random_names(df):\n",
    " #   df['Names'] = [fake.name() for _ in range(len(df))]\n",
    "  #  cols = ['Names'] + [col for col in df.columns if col != 'Names']  # Reorder columns\n",
    "   # return df[cols]\n",
    "    \n",
    "data.columns = data.columns.str.strip().str.lower()  # Remove spaces & lowercase\n",
    "print(data.columns)  \n",
    "\n",
    "# Converting 'issue_month' to a full date format, assuming the 1st of each month\n",
    "data['issue_date'] = pd.to_datetime(data['issue_date'])\n",
    "\n",
    "\n",
    "print(data['issue_date'].head())  # Check the first few values in 'issue_date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3d76786-a07c-4a8e-bf6f-8f4ff6c4a561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             names                  profession        loan_purpose  \\\n",
      "0      Ebuka Ajagu               Meme Director               other   \n",
      "1   Sandra Sanders                          rn  debt_consolidation   \n",
      "2  Danielle Bishop                 parts sales  debt_consolidation   \n",
      "3     Jill Jackson  human resources supervisor  debt_consolidation   \n",
      "4     Julie Fields        production scheduler  debt_consolidation   \n",
      "\n",
      "  total_credit_utilized loan_amount  interest_rate  term  ten_of monthly  \\\n",
      "0                 10000      20,000           7.50    36            58.0   \n",
      "1                14,848       25000          14.08    60            58.0   \n",
      "2                23,143       21500          11.99    60            48.0   \n",
      "3                80,746       23200           7.35    36            72.0   \n",
      "4                45,651       15000          14.08    60            35.0   \n",
      "\n",
      "   total_satoshis  total_dollars_spent payoff_date  \n",
      "0      29950504.0               2088.0    9/1/2020  \n",
      "1      32657074.0               3480.0    1/1/2023  \n",
      "2      27026544.0               2880.0    1/1/2023  \n",
      "3      35092296.0               2592.0    1/1/2021  \n",
      "4      19706855.0               2100.0    1/1/2023  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##this has a fuller table and will be exported out soon\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Convert dates to datetime format\n",
    "btc_data['bitcoin_date'] = pd.to_datetime(btc_data['bitcoin_date'])\n",
    "data['issue_date'] = pd.to_datetime(data['issue_date'])\n",
    "\n",
    "# Remove rows with null 'issue_date' values in the 'data' dataframe before merging\n",
    "data = data.dropna(subset=['issue_date'])  # Removes rows where 'issue_date' is null\n",
    "\n",
    "# Convert 'term' column to integer to avoid float issue in range\n",
    "data['term'] = data['term'].astype(int)\n",
    "\n",
    "# Merge the two datasets on the issue_date and bitcoin_date (nearest match for each person)\n",
    "merged_data = pd.merge_asof(data.sort_values('issue_date'), \n",
    "                            btc_data.sort_values('bitcoin_date'),\n",
    "                            left_on='issue_date', right_on='bitcoin_date', \n",
    "                            direction='nearest')\n",
    "\n",
    "# Initialize lists to store total sats and total dollars spent for each person\n",
    "total_satoshis_per_customer = []\n",
    "total_dollars_spent_per_customer = []\n",
    "\n",
    "# Iterate over each row to calculate sats and dollars spent for each customer\n",
    "for index, row in merged_data.iterrows():\n",
    "    # Extract relevant data for the current customer\n",
    "    monthly_spent = row['ten_of monthly']  # Monthly dollar spent\n",
    "    issue_date = row['issue_date']\n",
    "    term = row['term']\n",
    "    \n",
    "    # Initialize total sats counter and total dollars spent\n",
    "    total_satoshis = 0\n",
    "    total_dollars_spent = monthly_spent * term  # Correctly calculate total dollars spent over the loan term\n",
    "    \n",
    "    # Adjust the issue date to start from the next month\n",
    "    start_date = issue_date + pd.DateOffset(months=1)\n",
    "    \n",
    "    for month_offset in range(term):\n",
    "        # Calculate the first day of the month for this month in the term, starting from the next month\n",
    "        month_date = start_date + pd.DateOffset(months=month_offset)\n",
    "        month_date_first_day = month_date.replace(day=1)  # Ensure it's the 1st of the month\n",
    "        \n",
    "        # Find the corresponding 'one_dollar_sats' for this specific month\n",
    "        sats_per_dollar = btc_data.loc[btc_data['bitcoin_date'] == month_date_first_day, 'one_dollar_sats'].values\n",
    "        if sats_per_dollar.size > 0:\n",
    "            sats_per_dollar = sats_per_dollar[0]\n",
    "        else:\n",
    "            sats_per_dollar = 0  # If no data for that specific day, assume 0 sats\n",
    "        \n",
    "        # Calculate satoshis bought for the current month\n",
    "        satoshis_bought = monthly_spent * sats_per_dollar\n",
    "        total_satoshis += satoshis_bought  # Add to the total satoshis bought\n",
    "\n",
    "    # Append the total sats and total dollars spent for this customer\n",
    "    total_satoshis_per_customer.append(total_satoshis)\n",
    "    total_dollars_spent_per_customer.append(total_dollars_spent)\n",
    "\n",
    "# Add the total satoshis and total dollars spent columns to the merged_data DataFrame\n",
    "merged_data['total_satoshis'] = total_satoshis_per_customer\n",
    "merged_data['total_dollars_spent'] = total_dollars_spent_per_customer\n",
    "\n",
    "# Show the names, total sats accumulated, and total dollars spent\n",
    "final_result = merged_data[['names', 'profession', 'loan_purpose', 'total_credit_utilized', 'loan_amount', 'interest_rate', 'term', \n",
    "                            'ten_of monthly', 'total_satoshis', 'total_dollars_spent', 'payoff_date']]\n",
    "\n",
    "# Print out the result to check\n",
    "print(final_result.head())\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa04b599-29c0-4a10-9cd5-dbbd96364fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Null values found in 'issue_date' column. These rows will be removed.\n",
      "              Names         profession  job_length state homeownership  \\\n",
      "0       Ebuka Ajagu      Meme Director         5.0    TN          RENT   \n",
      "1  Stacey Craig DDS    delivery driver        10.0    CO          RENT   \n",
      "2    Christina King  operation manager        10.0    GA           OWN   \n",
      "3      Philip Gates     clinical nurse        10.0    IL           OWN   \n",
      "4        Jose Reyes        bar manager         6.0    NY          RENT   \n",
      "\n",
      "  annual_income monthly_wage  debt_to_income  total_credit_limit  \\\n",
      "0        50,000        4,167            0.05             20000.0   \n",
      "1        40,000        3,333           10.17             15262.0   \n",
      "2       105,000        8,750           10.03            112755.0   \n",
      "3       120,000       10,000           10.04             73599.0   \n",
      "4        65,000        5,417           10.08             49200.0   \n",
      "\n",
      "  total_credit_utilized  ... issue_date payoff_date   s&p_date     price  \\\n",
      "0                 10000  ... 2017-09-01    9/1/2020 2017-09-01  2,476.60   \n",
      "1                 7,461  ... 2018-01-01    1/1/2021 2018-01-02  2,695.80   \n",
      "2                41,644  ... 2018-01-01    1/1/2023 2018-01-02  2,695.80   \n",
      "3                43,865  ... 2018-01-01    1/1/2021 2018-01-02  2,695.80   \n",
      "4                38,594  ... 2018-01-01    1/1/2023 2018-01-02  2,695.80   \n",
      "\n",
      "  one_dollar_unit  Unnamed: 3  Unnamed: 4  Unnamed: 5 Unnamed: 6 Unnamed: 7  \n",
      "0          0.0004         NaN         NaN         NaN        NaN        NaN  \n",
      "1          0.0004         NaN         NaN         NaN        NaN        NaN  \n",
      "2          0.0004         NaN         NaN         NaN        NaN        NaN  \n",
      "3          0.0004         NaN         NaN         NaN        NaN        NaN  \n",
      "4          0.0004         NaN         NaN         NaN        NaN        NaN  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the S&P 500 data\n",
    "sp_data = pd.read_csv(r\"C:\\Users\\ebuca\\OneDrive\\Documents\\DA13\\Python\\projects\\Capstone_project\\sp_data.csv\")\n",
    "\n",
    "# Load the updated loan data\n",
    "data = pd.read_csv(r\"C:\\Users\\ebuca\\OneDrive\\Documents\\DA13\\Python\\projects\\Capstone_project\\updated_loan_data.csv\")\n",
    "\n",
    "# Convert date columns to datetime\n",
    "sp_data['s&p_date'] = pd.to_datetime(sp_data['s&p_date'])\n",
    "data['issue_date'] = pd.to_datetime(data['issue_date'])\n",
    "\n",
    "# Check and drop rows with null values in the issue_date column\n",
    "if data['issue_date'].isnull().any():\n",
    "    print(\"Warning: Null values found in 'issue_date' column. These rows will be removed.\")\n",
    "    data = data.dropna(subset=['issue_date'])\n",
    "\n",
    "# Ensure both tables are sorted by their respective date columns before merging\n",
    "sp_data = sp_data.sort_values('s&p_date')\n",
    "data = data.sort_values('issue_date')\n",
    "\n",
    "# Merge the two datasets on the issue_date and s&p_date (nearest match for each person)\n",
    "merged_data = pd.merge_asof(\n",
    "    data.sort_values('issue_date'), \n",
    "    sp_data.sort_values('s&p_date'),\n",
    "    left_on='issue_date', right_on='s&p_date', \n",
    "    direction='nearest'\n",
    ")\n",
    "\n",
    "# Now you can proceed with further processing...\n",
    "print(merged_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "412db3c4-e705-4c90-a111-3a173e821fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging the table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549b0a05-d753-4cf5-b515-ffa7e90919fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac21436-19a9-479f-983f-9a815fcdceef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
